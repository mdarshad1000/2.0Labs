"""
Graph/Atlas API Router - Research node generation endpoints
"""
import json
from typing import List, Optional
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

from services.openai_service import openai_service

router = APIRouter(prefix="/api/graph", tags=["graph"])


class DocumentInput(BaseModel):
    name: str
    content: str


class GenerateGraphRequest(BaseModel):
    query: str
    documents: List[DocumentInput]


class NodeInput(BaseModel):
    title: str
    content: List[str]


class ExpandNodeRequest(BaseModel):
    node: NodeInput
    documents: List[DocumentInput]
    query: Optional[str] = None


class MergeNodesRequest(BaseModel):
    nodes: List[NodeInput]


class SuggestMergeResponse(BaseModel):
    suggestions: List[str]


class SuggestExpandRequest(BaseModel):
    node: NodeInput
    documents: List[DocumentInput]


class CreateNodeRequest(BaseModel):
    prompt: str
    parent_node: Optional[NodeInput] = None
    documents: List[DocumentInput] = []


class NodeOutput(BaseModel):
    title: str
    content: List[str]
    color: str


class GenerateGraphResponse(BaseModel):
    nodes: List[NodeOutput]


class CreateNodeResponse(BaseModel):
    node: NodeOutput


@router.post("/generate", response_model=GenerateGraphResponse)
async def generate_graph(request: GenerateGraphRequest):
    """
    Generate research graph nodes from a query and documents.
    Uses GPT-4o to analyze documents and create structured knowledge nodes.
    """
    try:
        documents = [{"name": d.name, "content": d.content} for d in request.documents]
        result = await openai_service.generate_graph_nodes(
            query=request.query,
            documents=documents
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/generate/stream")
async def generate_graph_stream(request: GenerateGraphRequest):
    """
    Stream research graph nodes one at a time via Server-Sent Events.
    Nodes appear progressively as they're generated by GPT-4o.
    """
    documents = [{"name": d.name, "content": d.content} for d in request.documents]
    
    async def event_generator():
        try:
            async for event in openai_service.stream_graph_nodes(
                query=request.query,
                documents=documents
            ):
                yield f"data: {json.dumps(event)}\n\n"
            
            # Signal completion
            yield f"data: {json.dumps({'type': 'done'})}\n\n"
            
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'data': {'message': str(e)}})}\n\n"
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # Disable nginx buffering
        }
    )


@router.post("/expand", response_model=GenerateGraphResponse)
async def expand_node(request: ExpandNodeRequest):
    """
    Expand a node into more detailed sub-nodes.
    """
    try:
        documents = [{"name": d.name, "content": d.content} for d in request.documents]
        result = await openai_service.expand_graph_node(
            node_title=request.node.title,
            node_content=request.node.content,
            documents=documents,
            query=request.query
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/merge", response_model=CreateNodeResponse)
async def merge_nodes(request: MergeNodesRequest):
    """
    Merge multiple nodes into a synthesized summary node.
    """
    try:
        nodes = [{"title": n.title, "content": n.content} for n in request.nodes]
        result = await openai_service.merge_graph_nodes(nodes=nodes)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/create", response_model=CreateNodeResponse)
async def create_node(request: CreateNodeRequest):
    """
    Create a new node from a custom prompt.
    Optionally connected to a parent node for context.
    """
    try:
        parent = None
        if request.parent_node:
            parent = {
                "title": request.parent_node.title,
                "content": request.parent_node.content
            }
        
        documents = [{"name": d.name, "content": d.content} for d in request.documents]
        result = await openai_service.create_node_from_prompt(
            prompt=request.prompt,
            parent_node=parent,
            documents=documents
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/suggest-expand", response_model=SuggestMergeResponse)
async def suggest_expand(request: SuggestExpandRequest):
    """
    Generate AI suggestions for how to expand a specific node.
    """
    try:
        result = await openai_service.generate_expand_suggestions(
            node_title=request.node.title,
            node_content=request.node.content,
            documents=[{"name": d.name, "content": d.content} for d in request.documents]
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


class SuggestMergeRequest(BaseModel):
    source_node: NodeInput
    target_node: NodeInput


# Models moved to top


@router.post("/suggest-merge", response_model=SuggestMergeResponse)
async def suggest_merge(request: SuggestMergeRequest):
    """
    Generate AI suggestions for how to connect/merge two nodes.
    """
    try:
        result = await openai_service.generate_merge_suggestions(
            source_node={"title": request.source_node.title, "content": request.source_node.content},
            target_node={"title": request.target_node.title, "content": request.target_node.content}
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

